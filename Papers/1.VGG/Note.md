# VGG

## 1. 研究背景

**卷积神经网络**在**大规模图像和视频识别领域**发展迅猛

* 大规模公开数据集（ImageNet， CIFAR等）
* 高性能计算系统的应用

## 2. 研究空白

**网络深度**对性能的影响在此前尚未有具体研究


## 3. 模型架构设计

作者设计了五种不同的网络配置，以A~E标记

<div align="center">
    <img src="image/1.jpg" alt="table1" width="500">
</div>

### 3.1 输入

224x224的RGB图像，减去RGB均值

#### 预处理减去RGB均值的作用：

* 数据中心化
* 消除光照偏差
* 加速收敛

目前先进方法会使用**其他正则化方法**

### 3.2 卷积层

作者设计了两种卷积核，3x3和1x1 (1x1卷积核只在配置C中使用)

* 步长为**1**
* 3x3卷积核的周边填充为1像素，以保持卷积后分辨率不变

### 3.3 池化层

* 5个max-pooling层跟在某些卷积层后面（不是所有卷积层都跟pooling）
* Max-pooling在2×2像素窗口上执行，步长为2

### 3.4 全连接层
卷积层堆叠后跟随3个全连接层，前两个各有4096个通道，后一个有1000个通道，执行1000路ILSVRC分类，对应ImageNet数据集的1000个类别，最后通过一个softmax层输出概率。

### 3.5 激活函数
所有隐藏层间的连接使用ReLU激活函数：

$$
\mathrm{ReLU}(x) = \max(0, x)
$$

### 3.6 归一化
在**A-LRN**配置中，第一个卷积层后使用了LRN归一化，不过实验数据表明额外的归一化对结果没有提升，且会占用更多计算资源，因此其余配置没有再使用。

>局部响应归一化（Local Response Normalization, LRN）是一种在早期卷积神经网络中常用的归一化方法，旨在增强模型的泛化能力和抑制过拟合。其思想是模拟生物神经网络中的“侧抑制”机制，对相邻通道间的活动进行归一化：
>
>$$
>b_{x,y}^{i} = a_{x,y}^{i} \Big/ \left( k + \alpha \sum\limits_{j=\max(0,\,i-n/2)}^{\min(N-1,\,i+n/> 2)} (a_{x,y}^{j})^2 \right)^{\beta}
>$$
>
>其中：
>- $a_{x,y}^{i}$ 表示第 $i$ 个通道在位置 $(x, y)$ 的输入激活值；
>- $b_{x,y}^{i}$ 表示归一化后的结果；
>- $n$ 是归一化的相邻通道数；
>- $N$ 是总通道数；
>- $k, \alpha, \beta$ 是超参数，常用 $k=2$, $\alpha=10^{-4}$, $\beta=0.75$。
>
>LRN 通过让大的响应在归一化区域内抑制其他激活，有助于模型学习更加稀疏和有判别性的特征。

### 3.6 结构讨论

#### 与前人工作的主要区别

**传统方法（ILSVRC-2012/2013）：**
* Krizhevsky et al. (2012): 第一层使用11×11卷积，步长4
* Zeiler & Fergus (2013): 第一层使用7×7卷积，步长2

**VGG的创新：**
* 全程使用3×3小卷积核
* 步长为**1**，在每个像素上进行卷积

#### 为什么堆叠小卷积核更好？

**1. 感受野等效性**

* 2个3×3卷积层的等效感受野为5×5
* 3个3×3卷积层的等效感受野为7×7

> **感受野（Receptive Field）**：神经网络中某个神经元在输入空间（如原始图像）上所对应的区域大小。即：该神经元输出的计算会受输入中特定区域的像素影响。在卷积神经网络中，随着卷积层和池化层的堆叠，深层神经元的感受野会逐渐扩大，能够“看到”更大范围的输入内容，从而捕捉更高级、更全局的特征。

**2. 更多非线性（更强的判别能力）**

使用多个小核卷积层，相较于一个大核卷积层，可以引入**更多的非线性激活函数**，使决策函数更具判别性

**3. 参数量大幅减少**

假设输入和输出都有C个通道：
* 3个3×3层：参数量 = 3×(3²×C²) = 27C²
* 1个7×7层：参数量 = 7²×C² = 49C²
* 节省比例：(49-27)/49 ≈ **44.9%的参数减少**

**4. 隐式正则化**

模型设计可视为对7×7卷积滤波器施加正则化，强制其通过3×3滤波器分解

### 3.7 针对配置C (最常用模型) 的1x1卷积核的作用

在不影响卷积层感受野的情况下增加决策函数的非线性，源于"Network in Network"架构（Lin et al., 2014）

## 4. 分类框架（CLASSIFICATION FRAMEWORK）

### 4.1 训练（Training）

#### 4.1.1 优化方法

使用**mini-batch梯度下降（基于反向传播）+ 动量**优化多项式逻辑回归目标函数：

* Batch size：$256$
* Momentum：$0.9$

#### 4.1.2 正则化

* **权重衰减（Weight Decay）**：L2惩罚系数设为 $5\times10^{-4}$
* **Dropout**：前两个全连接层使用dropout ratio = $0.5$

#### 4.1.3 学习率策略

* 初始学习率：$10^{-2}$
* 当验证集准确率停止提升时，学习率除以10，总共降低3次
* 训练迭代次数：370K iterations (74 epochs)

尽管VGG网络参数更多、深度更深，但相比AlexNet需要更少的epoch就能收敛，原因是：
* 更大的深度和更小的卷积核尺寸带来的**隐式正则化**
* 特定层的**预初始化**

#### 4.1.4 权重初始化

**初始化策略：**
* 首先训练配置A
* 训练更深的网络时，用网络A的前4个卷积层和后3个全连接层初始化，中间层随机初始化
* 预初始化的层学习率不降低，允许其在学习过程中改变

>**随机初始化（中间层）：**
>* 权重：从均值为0、方差$10^{-2}$的正态分布采样
>* 偏置：初始化为0

#### 4.1.5 数据增强

**获取224×224输入图像的方法：**
* 从rescaled的训练图像中**随机裁剪**（每次SGD迭代，每张图像一个crop）
* **随机水平翻转**
* **随机RGB颜色偏移**

**训练尺度S（Training Scale）：**

训练尺度S定义为等比例缩放后的训练图像的最小边长。裁剪尺寸固定为224×224，但S可以取任何不小于224的值：
* $S = 224$：crop捕获整张图像统计信息
* $S >> 224$：crop对应图像的一小部分，包含小物体或物体部分

**两种设置训练尺度S的方法：**

1. **单尺度训练（Single-scale training）**
   * 固定S的值
   * 实验中评估了两个固定尺度：$S = 256$ 和 $S = 384$
   * 先训练S = 256的网络，再用其权重初始化S = 384的网络（使用更小的初始学习率10⁻³）

2. **多尺度训练（Multi-scale training）**
   * 每张训练图像的S从范围 $[S_{min},S_{max}]$ 中随机采样
   * 实验使用 $S_{ming=256}$, $S_{max}=512$
   * 可看作**尺度抖动的训练集增强**，使单个模型能够识别多种尺度的物体

### 4.2 测试（Testing）

给定一个训练好的ConvNet和输入图像，分类过程如下：

#### 4.2.1 测试流程

1. **图像缩放**：等比例缩放到预定义的最小边长Q（测试尺度）
   * Q不一定等于训练尺度S
   * 对每个S使用多个Q值可以提升性能

2. **密集应用网络（Dense Application）**
   * 全连接层转换为卷积层：
     - 第1个FC层 → 7×7卷积层
     - 后2个FC层 → 1×1卷积层
   * 得到的全卷积网络应用于整张（未裁剪的）图像
   * 结果是一个**类别分数图（class score map）**，通道数等于类别数，空间分辨率取决于输入图像尺寸

3. **空间平均池化**：对类别分数图进行空间平均（sum-pooled），得到固定大小的类别分数向量

4. **测试增强**：水平翻转图像，将原始图像和翻转图像的soft-max类别后验概率平均，得到最终分数

#### 4.2.2 Dense vs Multi-crop评估

**Dense评估的优势：**
* 全卷积网络应用于整张图像，无需在测试时采样多个crops
* 更高效，不需要为每个crop重新计算网络

**Multi-crop评估：**
* 使用大量crops（如Szegedy et al. 2014）可以提高准确率
* 对输入图像进行更精细的采样
* VGG实验使用50 crops per scale（5×5网格 + 2次翻转），3个尺度共150 crops

**两种方法的互补性：**
* Multi-crop和Dense评估对卷积边界条件的处理不同
* Multi-crop：卷积特征图用零填充
* Dense：填充自然来自图像的相邻部分，增加网络的有效感受野，捕获更多上下文

### 4.3 实现细节（Implementation Details）

* **框架**：基于C++ Caffe Toolkits
* **多GPU训练**：
  - 数据并行
  - GPU间梯度计算同步
* **硬件**：4个NVIDIA Titan Black GPUs
* **训练时间**：单个网络训练2-3周

## 5. 分类实验（CLASSIFICATION EXPERIMENTS）

### 5.1 数据集

ILSVRC-2012数据集 (用于ILSVRC 2012-2014 challenges)
* **1000个类别**
* 训练集：1.3M图像，验证集：50K图像，测试集：100K图像

**评估指标：**
> **Top-1 error**: 模型预测概率**最高**的类别不等于真实类别的比例
> **Top-5 error**: 模型预测概率**最高的前5个**类别中没有包含真实类别的比例

### 5.2 单尺度评估（Single Scale Evaluation）

**测试设置**：
* 固定$S$训练：$Q = S$
* 抖动$S$训练：$Q = 0.5(S_{min} + S_{max})$

**主要发现**：

1. **LRN无效**：配置A-LRN与A性能相同，更深架构不再使用LRN

2. **深度提升性能**：错误率随深度增加而降低（11层→19层）

3. **3×3优于1×1**：配置D（全3×3卷积）优于配置C（含3个1×1卷积），说明捕获空间上下文很重要

4. **深度网络优于浅层网络**：配置B比5层5×5卷积的浅层网络Top-1 error低7%

5. **尺度抖动有效**：训练时使用$S \in [256; 512]$比固定$S$效果显著更好

### 5.3 多尺度评估（Multi-Scale Evaluation）

测试时使用多个缩放版本的图像，平均类别后验概率。

**测试尺度设置**：
* 固定$S$训练：$Q = \{S-32, S, S+32\}$
* 可变$S$训练：$Q = \{256, 384, 512\}$

**结果**：
* 多尺度测试优于单尺度
* 配置D和E表现最佳
* **最佳单网络性能**（配置E）：
  - 验证集：24.8% (top-1) / 7.5% (top-5)
  - 测试集：7.3% (top-5)

### 5.4 Multi-crop评估

比较dense评估和multi-crop评估（150 crops = 50 crops/scale × 3 scales）

**结果**：
* Multi-crop略优于dense
* 两者**互补**，组合效果最佳：
  - Dense：7.5% (top-5)
  - Multi-crop：7.4% (top-5)
  - 组合：7.1-7.2% (top-5)

### 5.5 模型融合（ConvNet Fusion）

通过平均多个模型的soft-max类别后验概率提升性能。

**结果**：
* ILSVRC提交（7个网络）：7.3% 测试error
* 提交后（2个网络D+E）：
  - Dense评估：7.0%
  - Dense + multi-crop：6.8%

### 5.6 与最先进方法对比

**ILSVRC-2014分类任务**：VGG团队获得**第2名**

| 方法 | 单网络 (top-5) | 多网络 (top-5) |
|------|---------------|---------------|
| **VGG** | **7.0%** | **6.8%** (2 nets) |
| GoogLeNet | 7.9% | 6.7% (7 nets) |
| Zeiler & Fergus | 16.1% | 14.8% (6 nets) |
| Krizhevsky et al. | 18.2% | 16.4% (5 nets) |

**关键成果**：
* 单网络性能**超越GoogLeNet** 0.9个百分点
* 仅用2个模型达到6.8%，模型数远少于竞争对手
* 证明传统ConvNet架构通过**增加深度**即可大幅提升性能


